<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Learning-Sharing-Recording" href="https://lzq-cv.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Learning-Sharing-Recording" href="https://lzq-cv.github.io/atom.xml"><link rel="alternate" type="application/json" title="Learning-Sharing-Recording" href="https://lzq-cv.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="CV"><link rel="canonical" href="https://lzq-cv.github.io/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/"><title>2D视觉和3D视觉的主流技术栈 - Opencv - Computer-Vision | LZQ's Blog = Learning-Sharing-Recording = To be,or not to be,that is the question</title><meta name="generator" content="Hexo 8.0.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">2D视觉和3D视觉的主流技术栈</h1><div class="meta"><span class="item" title="Created: 2025-09-27 09:38:14"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2025-09-27T09:38:14+08:00">2025-09-27</time> </span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">Symbols count in article</span> <span>3.4k</span> <span class="text">words</span> </span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">Reading time</span> <span>3 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">LZQ's Blog</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://lzq-cv.oss-cn-shanghai.aliyuncs.com/05bca4a24ba140b8b8e68b7be3cdc18a.jpg"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Computer-Vision/" itemprop="item" rel="index" title="In Computer-Vision"><span itemprop="name">Computer-Vision</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Computer-Vision/Opencv/" itemprop="item" rel="index" title="In Opencv"><span itemprop="name">Opencv</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://lzq-cv.github.io/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="LZQ"><meta itemprop="description" content="To be,or not to be,that is the question, CV Engineer"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Learning-Sharing-Recording"></span><div class="body md" itemprop="articleBody"><p>计算机视觉（CV）领域的主流技术栈，2D 视觉和 3D 视觉的技术、应用与区别。</p><h3 id="一-计算机视觉技术栈总览"><a class="anchor" href="#一-计算机视觉技术栈总览">#</a> 一、 计算机视觉技术栈总览</h3><p>计算机视觉的技术栈可以大致分为三个层次，从底层的基础工具到顶层的具体应用：</p><ol><li><p><strong>底层基础层：</strong></p><ul><li><strong>编程语言：</strong> <strong>Python</strong> 是绝对的主流，因其丰富的库和社区生态。C++ 在需要高性能、低延迟的场合（如嵌入式、自动驾驶）中不可或缺。</li><li><strong>数学基础：</strong> 线性代数、微积分、概率论、数值分析是理解算法的基石。</li><li><strong>硬件：</strong> <strong>GPU（NVIDIA）</strong> 是训练和部署深度学习模型的核心。专用的 AI 芯片（如 Google TPU, NVIDIA Jetson, Intel Movidius）也在边缘计算中扮演重要角色。</li></ul></li><li><p><strong>核心工具与框架层：</strong></p><ul><li><strong>深度学习框架：</strong><ul><li><strong>PyTorch：</strong> 当前学术界和工业界的首选，以其动态图和简洁的 API 深受研究人员喜爱。</li><li><strong>TensorFlow：</strong> 由 Google 支持，在工业界部署（尤其是使用 TensorFlow Lite, TensorRT 时）仍有强大优势。Keras 是其高级 API，易于上手。</li></ul></li><li><strong>传统计算机视觉库：</strong><ul><li><strong>OpenCV：</strong> 计算机视觉的 “瑞士军刀”，提供了从图像 / 视频读写、预处理、几何变换、特征提取到目标检测（传统方法）等海量功能，是必备基础库。</li></ul></li><li><strong>3D 视觉专用库：</strong><ul><li><strong>Open3D：</strong> 一个现代化的 3D 数据处理库，支持点云、网格的可视化、配准、重建等。</li><li><strong>PCL：</strong> 点云库，功能非常强大但接口相对陈旧，在 C++ 项目中广泛使用。</li><li><strong>VTK, ITK：</strong> 主要用于科学可视化和医学图像处理。</li></ul></li></ul></li><li><p><strong>模型与算法层：</strong></p><ul><li>这是技术栈的核心，下面将分 2D 和 3D 详细展开。</li></ul></li></ol><hr><h3 id="二-2d-计算机视觉"><a class="anchor" href="#二-2d-计算机视觉">#</a> 二、 2D 计算机视觉</h3><p>2D 视觉处理的是像素矩阵，即我们常见的 RGB 或灰度图像。</p><h4 id="核心任务与技术"><a class="anchor" href="#核心任务与技术">#</a> 核心任务与技术</h4><ol><li><p><strong>图像分类：</strong> 判断图像中包含什么物体。</p><ul><li><strong>核心技术：</strong> 卷积神经网络。</li><li><strong>经典模型：</strong><ul><li><strong>开创者：</strong> AlexNet (2012)</li><li><strong>深度代表：</strong> VGGNet</li><li><strong>革新者：</strong> GoogLeNet (Inception 模块), ResNet (残差连接，解决了深层网络梯度消失问题)，这些模型至今仍是强大的<strong>骨干网络</strong>。</li></ul></li></ul></li><li><p><strong>目标检测：</strong> 找出图像中所有感兴趣物体的位置（用边界框表示）和类别。</p><ul><li><strong>两阶段检测器（精度高，速度慢）：</strong><ul><li><strong>R-CNN 系列：</strong> R-CNN -&gt; Fast R-CNN -&gt; <strong>Faster R-CNN</strong>。先产生候选区域，再对区域进行分类和微调。</li></ul></li><li><strong>单阶段检测器（速度快，精度可媲美两阶段）：</strong><ul><li><strong>YOLO 系列：</strong> 特别是 <strong>v3, v5, v8, v9</strong>，将检测视为单一的回归问题，速度极快，是实时应用的首选。</li><li><strong>SSD：</strong> 另一个经典的单阶段检测器。</li></ul></li></ul></li><li><p><strong>图像分割：</strong> 对每个像素进行分类，为每个物体生成精确的轮廓。</p><ul><li><strong>语义分割：</strong> 只区分类别，不区分个体（例如，图中所有的 “人” 都是同一类）。<ul><li><strong>核心架构：</strong> <strong>编码器 - 解码器</strong>结构。编码器（如 ResNet）提取特征，解码器（如<strong> U-Net</strong>）恢复空间维度并进行像素级预测。<strong>DeepLab</strong> 系列（使用空洞卷积）也是主流。</li></ul></li><li><strong>实例分割：</strong> 既区分类别，也区分不同的个体（例如，区分出第一个人，第二个人）。<ul><li><strong>经典模型：</strong> <strong>Mask R-CNN</strong>，是在 Faster R-CNN 基础上的扩展，增加了一个分支来预测每个目标的二值掩码。</li></ul></li></ul></li><li><p><strong>关键点检测：</strong> 检测物体上具有特定意义的点。</p><ul><li><strong>应用：</strong> 人脸关键点（眼、鼻、嘴）、人体姿态估计（关节点的位置）。</li><li><strong>典型方法：</strong> 通常建模为热图回归问题，即预测每个关键点可能出现的概率分布图。<strong>HRNet</strong> 是当前人体姿态估计的 SOTA 方法之一。</li></ul></li><li><p><strong>图像生成与编辑：</strong></p><ul><li><strong>生成对抗网络（GANs）：</strong> 如 StyleGAN 系列，用于生成逼真的人脸、艺术品等。</li><li><strong>扩散模型：</strong> 如 Stable Diffusion、DALL-E，已成为图像生成的新范式，生成质量更高、更可控。</li></ul></li></ol><h4 id="2d视觉技术栈总结"><a class="anchor" href="#2d视觉技术栈总结">#</a> 2D 视觉技术栈总结</h4><ul><li><strong>输入：</strong> RGB 图像（H x W x 3）。</li><li><strong>核心网络：</strong> <strong>卷积神经网络</strong>。</li><li><strong>主要框架：</strong> PyTorch / TensorFlow + OpenCV。</li><li><strong>趋势：</strong> Vision Transformer (ViT) 正在挑战 CNN 的统治地位，显示出强大的性能。轻量化模型（如 MobileNet, ShuffleNet）用于移动端和嵌入式设备是重要方向。</li></ul><hr><h3 id="三-3d-计算机视觉"><a class="anchor" href="#三-3d-计算机视觉">#</a> 三、 3D 计算机视觉</h3><p>3D 视觉旨在理解和重建三维世界的信息，其输入和数据表示形式远比 2D 丰富。</p><h4 id="数据表示形式"><a class="anchor" href="#数据表示形式">#</a> 数据表示形式</h4><ol><li><strong>深度图：</strong> 每个像素的值代表该点到相机的距离。通常由 RGB-D 相机（如 Kinect, RealSense）或立体视觉直接获得。</li><li><strong>点云：</strong> 一组三维空间中的点（x, y, z）的集合，可以包含颜色、法向量等信息。是激光雷达的直接输出。</li><li><strong>体素网格：</strong> 将 3D 空间离散化为一个个小立方体（类似于 2D 的像素），是 3D 卷积的自然延伸，但内存消耗大。</li><li><strong>网格：</strong> 由顶点、边和面（通常是三角面片）构成的曲面，是 3D 建模和渲染的通用格式。</li><li><strong>多视图图像：</strong> 从不同视角拍摄的同一物体的多张 2D 图像，可通过运动恢复结构技术生成 3D 模型。</li></ol><h4 id="核心任务与技术-2"><a class="anchor" href="#核心任务与技术-2">#</a> 核心任务与技术</h4><ol><li><p><strong>3D 重建：</strong> 从一组 2D 图像或深度传感器数据中恢复物体的 3D 模型。</p><ul><li><strong>运动恢复结构：</strong> 从多视角图像中计算相机姿态和稀疏的 3D 点云。</li><li><strong>多视图立体视觉：</strong> 在 SfM 的基础上，生成稠密的 3D 点云或网格。</li><li><strong>深度学习方法：</strong> 如 MVSNet 等，利用神经网络直接从多视图图像中学习生成深度图或点云。</li></ul></li><li><p><strong>点云处理：</strong></p><ul><li><strong>点云分类与分割：</strong> 对点云中的每个点或整个点云进行分类。<ul><li><strong>开创性工作：</strong> <strong>PointNet</strong> / <strong>PointNet++</strong>，直接处理无序的点云集合。</li><li><strong>后续发展：</strong> 基于图卷积、稀疏卷积（如<strong> Minkowski Engine</strong>）的方法能更好地捕捉局部特征。</li></ul></li><li><strong>点云配准：</strong> 将不同视角扫描的点云对齐到同一个坐标系下。经典算法有 ICP，深度学习如 PointNetLK, DCP 等。</li></ul></li><li><p><strong>3D 目标检测：</strong></p><ul><li><strong>基于 LiDAR：</strong> 直接在点云中检测 3D bounding box（包含中心点、长宽高、朝向）。<strong>VoxelNet</strong>、<strong>PointPillars</strong>、<strong>SECOND</strong> 是经典且高效的模型。</li><li><strong>基于视觉：</strong> 仅使用单目或双目 RGB 图像来估计 3D 框，难度更大，是当前研究热点。</li><li><strong>多模态融合：</strong> 结合相机（RGB）和激光雷达（点云）的信息，提升检测精度，是自动驾驶领域的核心。</li></ul></li><li><p><strong>SLAM：</strong> 即时定位与地图构建。</p><ul><li>机器人在未知环境中移动，同时估计自身位置并构建环境地图。</li><li><strong>视觉 SLAM：</strong> 使用单目、双目或 RGB-D 相机作为主要传感器。ORB-SLAM 系列是里程碑式的工作。</li><li><strong>激光 SLAM：</strong> 使用激光雷达，如 LOAM、Cartographer，通常更精确。</li></ul></li><li><p><strong>神经辐射场：</strong> 一种革命性的 3D 场景表示和渲染技术。</p><ul><li><strong>核心思想（NeRF）：</strong> 用一个神经网络将空间位置和观看视角映射为颜色和密度，从而可以从任意视角生成逼真的新视图。衍生出了大量快速、动态的 NeRF 变体。</li></ul></li></ol><h4 id="3d视觉技术栈总结"><a class="anchor" href="#3d视觉技术栈总结">#</a> 3D 视觉技术栈总结</h4><ul><li><strong>输入：</strong> 点云、深度图、多视图图像等。</li><li><strong>核心挑战：</strong> 数据的<strong>无序性</strong>（点云）、<strong>稀疏性</strong>、<strong>非结构化</strong>。</li><li><strong>核心技术：</strong><ul><li><strong>传统几何方法：</strong> 多视图几何、光束法平差、ICP。</li><li><strong>深度学习方法：</strong> 针对 3D 数据特化的网络（PointNet 系列、3D 稀疏卷积、Transformer）。</li></ul></li><li><strong>主要框架：</strong> PyTorch / TensorFlow + Open3D / PCL。</li></ul><hr><h3 id="四-2d视觉-vs-3d视觉-对比总结"><a class="anchor" href="#四-2d视觉-vs-3d视觉-对比总结">#</a> 四、 2D 视觉 vs. 3D 视觉 对比总结</h3><table><thead><tr><th style="text-align:left">特性</th><th style="text-align:left">2D 计算机视觉</th><th style="text-align:left">3D 计算机视觉</th></tr></thead><tbody><tr><td style="text-align:left"><strong>数据输入</strong></td><td style="text-align:left">二维像素矩阵（RGB / 灰度图）</td><td style="text-align:left">点云、深度图、多视图图像、网格等</td></tr><tr><td style="text-align:left"><strong>信息维度</strong></td><td style="text-align:left">缺少深度和真实的几何信息</td><td style="text-align:left">包含丰富的三维几何和空间关系信息</td></tr><tr><td style="text-align:left"><strong>核心任务</strong></td><td style="text-align:left">分类、检测、分割（在像素层面）</td><td style="text-align:left">3D 重建、3D 检测、SLAM、点云处理</td></tr><tr><td style="text-align:left"><strong>核心技术</strong></td><td style="text-align:left">卷积神经网络（CNN），Transformer</td><td style="text-align:left">多视图几何、点云网络（PointNet）、3D 卷积、神经辐射场（NeRF）</td></tr><tr><td style="text-align:left"><strong>应用场景</strong></td><td style="text-align:left">图像检索、照片美化、安防监控、图像内容审核</td><td style="text-align:left"><strong>自动驾驶</strong>、<strong>机器人导航</strong>、<strong>AR/VR</strong>、无人机、工业三维测量</td></tr><tr><td style="text-align:left"><strong>数据获取</strong></td><td style="text-align:left">简单、廉价（普通摄像头）</td><td style="text-align:left">相对复杂、昂贵（RGB-D 相机、激光雷达）或需要计算（SfM）</td></tr><tr><td style="text-align:left"><strong>挑战</strong></td><td style="text-align:left">光照变化、遮挡、视角变化、类内差异</td><td style="text-align:left">数据稀疏、噪声大、计算复杂度高、标注成本极高</td></tr></tbody></table><h3 id="五-融合与未来趋势"><a class="anchor" href="#五-融合与未来趋势">#</a> 五、 融合与未来趋势</h3><p>未来的发展方向绝不是 2D 和 3D 的割裂，而是<strong>深度融合</strong>：</p><ul><li><strong>多模态学习：</strong> 将 2D 图像的丰富纹理和语义信息与 3D 数据的精确几何结构相结合。例如，在自动驾驶中，用 2D 检测的结果辅助 3D 检测，或者用 3D 信息为 2D 分割提供空间上下文。</li><li><strong>2D 引导的 3D 理解：</strong> 利用在大型 2D 图像数据集（如 ImageNet）上预训练的模型，通过知识蒸馏或迁移学习来提升 3D 模型的性能，解决 3D 数据稀缺的问题。</li><li><strong>AIGC 在 3D 中的应用：</strong> 利用扩散模型等生成式 AI 技术，从文本或单张图像直接生成高质量的 3D 模型（如 TripoSR、Shap-E 等），这将极大降低 3D 内容创作的门槛。</li></ul><div class="tags"><a href="/tags/CV/" rel="tag"><i class="ic i-tag"></i> CV</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2025-09-29 09:06:08" itemprop="dateModified" datetime="2025-09-29T09:06:08+08:00">2025-09-29</time></span></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>LZQ <i class="ic i-at"><em>@</em></i>Learning-Sharing-Recording</li><li class="link"><strong>Post link: </strong><a href="https://lzq-cv.github.io/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/" title="2D视觉和3D视觉的主流技术栈">https://lzq-cv.github.io/2D视觉和3D视觉的主流技术栈/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/LAMP%E5%92%8CLNMP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8C%BA%E5%88%AB/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;lzq-cv.oss-cn-shanghai.aliyuncs.com&#x2F;173196-qi_fen-yi_shu-kong_jian-ji_yun-wu_ye-x750.jpg" title="LAMP和LNMP服务器架构的区别"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i></span><h3>LAMP和LNMP服务器架构的区别</h3></a></div><div class="item right"><a href="/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;lzq-cv.oss-cn-shanghai.aliyuncs.com&#x2F;149624-tian_kong-xing_neng-yi_shu-yin_le_hui-ren_qun-3840x2160.jpg" title="2D视觉的主流应用场景"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> Opencv</span><h3>2D视觉的主流应用场景</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%8A%80%E6%9C%AF%E6%A0%88%E6%80%BB%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">一、 计算机视觉技术栈总览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C-2d-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="toc-number">2.</span> <span class="toc-text">二、 2D 计算机视觉</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E4%BB%BB%E5%8A%A1%E4%B8%8E%E6%8A%80%E6%9C%AF"><span class="toc-number">2.1.</span> <span class="toc-text">核心任务与技术</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2d%E8%A7%86%E8%A7%89%E6%8A%80%E6%9C%AF%E6%A0%88%E6%80%BB%E7%BB%93"><span class="toc-number">2.2.</span> <span class="toc-text">2D 视觉技术栈总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89-3d-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="toc-number">3.</span> <span class="toc-text">三、 3D 计算机视觉</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%A4%BA%E5%BD%A2%E5%BC%8F"><span class="toc-number">3.1.</span> <span class="toc-text">数据表示形式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E4%BB%BB%E5%8A%A1%E4%B8%8E%E6%8A%80%E6%9C%AF-2"><span class="toc-number">3.2.</span> <span class="toc-text">核心任务与技术</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3d%E8%A7%86%E8%A7%89%E6%8A%80%E6%9C%AF%E6%A0%88%E6%80%BB%E7%BB%93"><span class="toc-number">3.3.</span> <span class="toc-text">3D 视觉技术栈总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B-2d%E8%A7%86%E8%A7%89-vs-3d%E8%A7%86%E8%A7%89-%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">四、 2D 视觉 vs. 3D 视觉 对比总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%94-%E8%9E%8D%E5%90%88%E4%B8%8E%E6%9C%AA%E6%9D%A5%E8%B6%8B%E5%8A%BF"><span class="toc-number">5.</span> <span class="toc-text">五、 融合与未来趋势</span></a></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li class="active"><a href="/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/" rel="bookmark" title="2D视觉和3D视觉的主流技术栈">2D视觉和3D视觉的主流技术栈</a></li><li><a href="/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" rel="bookmark" title="2D视觉的主流应用场景">2D视觉的主流应用场景</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="LZQ" data-src="/images/avatar.jpg"><p class="name" itemprop="name">LZQ</p><div class="description" itemprop="description">CV Engineer</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">14</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">4</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">9</span> <span class="name">tags</span></a></div></nav><div class="social"><span class="exturl item bilibili" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vODI2ODE4NDY/c3BtX2lkX2Zyb209MzMzLjEwMDcuMC4w" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;82681846?spm_id_from&#x3D;333.1007.0.0"><i class="ic i-bilibili"></i></span> <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0xaUS1DVg==" title="https:&#x2F;&#x2F;github.com&#x2F;LZQ-CV"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9tYW8tcWl1LWNoYW5nLWx6cQ==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mao-qiu-chang-lzq"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTMzNjM5NDU5MTA=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;3363945910"><i class="ic i-cloud-music"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>Posts</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/LAMP%E5%92%8CLNMP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8C%BA%E5%88%AB/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/Artificial-Intelligence/" title="In Artificial-Intelligence">Artificial-Intelligence</a> <i class="ic i-angle-right"></i> <a href="/categories/Artificial-Intelligence/Deep-Learning/" title="In Deep-Learning">Deep-Learning</a></div><span><a href="/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA/" title="PyTorch深度学习框架搭建">PyTorch深度学习框架搭建</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E4%BD%BF%E7%94%A8PICGO-GitHub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/" title="使用PICGO-GitHub搭建个人图床">使用PICGO-GitHub搭建个人图床</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/shoka%E4%B8%BB%E9%A2%98%E9%83%A8%E7%BD%B2/" title="shoka主题部署">shoka主题部署</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Vision/" title="In Computer-Vision">Computer-Vision</a> <i class="ic i-angle-right"></i> <a href="/categories/Computer-Vision/Opencv/" title="In Opencv">Opencv</a></div><span><a href="/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" title="2D视觉的主流应用场景">2D视觉的主流应用场景</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E4%BD%BF%E7%94%A8PICGO-CloudflarR2%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/" title="使用PICGO-CloudflarR2搭建个人图床">使用PICGO-CloudflarR2搭建个人图床</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/HEXO%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" title="HEXO博客搭建">HEXO博客搭建</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E5%85%8D%E8%B4%B9%E5%9B%BE%E5%BA%8A%E8%B8%A9%E5%9D%91/" title="免费图床踩坑">免费图床踩坑</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/LAMP%E5%92%8CLNMP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8C%BA%E5%88%AB/" title="LAMP和LNMP服务器架构的区别">LAMP和LNMP服务器架构的区别</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E7%A1%AC%E4%BB%B6%E5%A6%82%E4%BD%95%E9%80%89%E5%9E%8B/" title="机器视觉硬件如何选型">机器视觉硬件如何选型</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E4%BD%BF%E7%94%A8PICGO-%E9%98%BF%E9%87%8C%E4%BA%91OSS%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/" title="使用PICGO-阿里云OSS搭建个人图床">使用PICGO-阿里云OSS搭建个人图床</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2024 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">LZQ @ LZQ's Blog</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="Symbols count total">33k words</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="Reading time total">30 mins.</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2D视觉和3D视觉的主流技术栈/",favicon:{show:"（●´3｀●）Nice to meet you.",hide:"(´Д｀)You'll be back !!!"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>