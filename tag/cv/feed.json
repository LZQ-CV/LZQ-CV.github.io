{
    "version": "https://jsonfeed.org/version/1",
    "title": "Learning-Sharing-Recording • All posts by \"cv\" tag",
    "description": "CV Engineer",
    "home_page_url": "https://LZQ-CV.github.io",
    "items": [
        {
            "id": "https://lzq-cv.github.io/2025/09/27/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/",
            "url": "https://lzq-cv.github.io/2025/09/27/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/",
            "title": "2D视觉的主流应用场景",
            "date_published": "2025-09-27T01:45:29.000Z",
            "content_html": "<h3 id=\"2d视觉主流应用场景与技术栈详解\"><a class=\"markdownIt-Anchor\" href=\"#2d视觉主流应用场景与技术栈详解\">#</a> 2D 视觉主流应用场景与技术栈详解</h3>\n<p>主流的 2D 视觉应用分为以下几个大类。</p>\n<hr>\n<h4 id=\"1-安防与监控\"><a class=\"markdownIt-Anchor\" href=\"#1-安防与监控\">#</a> 1. 安防与监控</h4>\n<p>这是 2D 视觉最经典、最广泛的应用领域。</p>\n<ul>\n<li>\n<p><strong>核心任务：</strong></p>\n<ul>\n<li><strong>人脸识别与身份验证：</strong> 门禁系统、手机解锁、公共安全排查。</li>\n<li><strong>人体检测与行为分析：</strong> 入侵检测、人群密度估计、徘徊检测、跌倒检测、打架斗殴识别。</li>\n<li><strong>车辆识别与交通监控：</strong> 车牌识别、车辆违章检测（闯红灯、压线）、交通流量分析。</li>\n<li><strong>物体遗留 / 消失检测：</strong> 在机场、火车站等场景检测可疑包裹。</li>\n</ul>\n</li>\n<li>\n<p><strong>主流技术栈：</strong></p>\n<ul>\n<li><strong>检测模型：</strong>\n<ul>\n<li><strong>YOLO 系列 (v5, v8, v9)：</strong> 绝对是该领域的首选，因其极高的速度和良好的精度，非常适合实时视频流分析。</li>\n<li><strong>SSD, RetinaNet：</strong> 也是常用的单阶段检测器。</li>\n</ul>\n</li>\n<li><strong>识别 / 分类模型：</strong>\n<ul>\n<li><strong>人脸识别：</strong> 使用专门的人脸检测（如 MTCNN、RetinaFace）加上人脸识别模型（如<strong> ArcFace</strong>、FaceNet、CosFace）。这些模型将人脸图像映射为一个高维特征向量，通过比对向量相似度进行身份识别。</li>\n<li><strong>行为识别：</strong> 相对复杂，通常需要处理视频序列。技术包括：\n<ul>\n<li><strong>3D CNN：</strong> 直接处理视频片段。</li>\n<li><strong>CNN + RNN/LSTM：</strong> 用 CNN 提取每一帧的特征，再用 RNN/LSTM 学习时序关系。</li>\n<li><strong>基于 Transformer 的方法：</strong> 如 TimeSformer，更好地捕捉长距离依赖。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>关键工具：</strong>\n<ul>\n<li><strong>OpenCV：</strong> 用于视频流捕获、图像预处理、绘制检测框、车牌识别中的字符分割等。</li>\n<li><strong>深度学习框架：</strong> PyTorch（研究和新模型部署主流）、TensorFlow（现有系统较多）。</li>\n<li><strong>部署工具：</strong> <strong>NVIDIA TensorRT</strong>（用于在 NVIDIA GPU 上极致加速推理）、<strong>OpenVINO</strong>（用于 Intel CPU/GPU 等硬件）。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>实际考量：</strong></p>\n<ul>\n<li><strong>实时性要求极高：</strong> 模型必须轻量化，通常需要在边缘设备（如 Jetson Nano、华为 Atlas）上运行。</li>\n<li><strong>光照、角度变化大：</strong> 要求模型有很强的鲁棒性，数据增强（如随机亮度、对比度变化）非常重要。</li>\n<li><strong>隐私问题：</strong> 需要遵循相关法律法规。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"2-工业质检与自动化\"><a class=\"markdownIt-Anchor\" href=\"#2-工业质检与自动化\">#</a> 2. 工业质检与自动化</h4>\n<p>这是 2D 视觉在工业界创造巨大价值的核心应用。</p>\n<ul>\n<li>\n<p><strong>核心任务：</strong></p>\n<ul>\n<li><strong>缺陷检测：</strong> 检测产品表面的划痕、凹陷、污点、毛刺等。</li>\n<li><strong>分类与分拣：</strong> 根据外观对产品进行合格 / 不合格分类，或按不同品类分拣。</li>\n<li><strong>定位与引导：</strong> 精确识别零件的位置和姿态，引导机械臂进行抓取、装配。</li>\n<li><strong>OCR 读取：</strong> 读取产品上的生产日期、批次号、序列号。</li>\n</ul>\n</li>\n<li>\n<p><strong>主流技术栈：</strong></p>\n<ul>\n<li><strong>缺陷检测：</strong>\n<ul>\n<li><strong>传统方法：</strong> 在规则、可控的照明环境下，传统算法依然非常有效且快速。例如，使用<strong> Blob 分析</strong>（找连通域）、<strong>模板匹配</strong>、<strong>形态学操作</strong>、<strong>频域滤波</strong>（如傅里叶变换找周期性缺陷）等。<strong>Halcon</strong> 和 <strong>VisionPro</strong> 是商业软件中的佼佼者。</li>\n<li><strong>深度学习方法：</strong> 对于复杂、不规则的缺陷，深度学习是更好的选择。\n<ul>\n<li><strong>语义分割：</strong> <strong>U-Net</strong> 及其变体是主流，可以像素级精确地定位缺陷区域。</li>\n<li><strong>生成式方法：</strong> 使用<strong>自编码器</strong> 或<strong>生成对抗网络</strong> 学习正常样本的特征，然后通过重建误差来检测异常（缺陷被视为异常）。这种方法特别适合<strong>缺陷样本稀少</strong>的场景。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>定位与 OCR：</strong>\n<ul>\n<li><strong>定位：</strong> 通常使用<strong>模板匹配</strong>（传统）或训练一个目标检测模型（如 YOLO）来预测物体的边界框或角点。</li>\n<li><strong>OCR：</strong> 通用场景可用 <strong>PaddleOCR</strong>、<strong>Tesseract</strong>。工业场景中字符通常规则且背景固定，也可以自己训练 CRNN（CNN+RNN+CTC）等模型，精度更高。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>实际考量：</strong></p>\n<ul>\n<li><strong>环境可控：</strong> 光照、相机位置、背景都是固定的，这是与安防场景的最大不同。</li>\n<li><strong>精度要求极高：</strong> 漏检和误检的成本很高，模型评估指标（如 mAP, IoU）要求严格。</li>\n<li><strong>速度要求：</strong> 需跟上生产线节奏，但通常不如安防实时性要求高。</li>\n<li><strong>数据瓶颈：</strong> 缺陷样本难以收集，小样本学习和无监督 / 半监督方法备受关注。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"3-医疗影像分析\"><a class=\"markdownIt-Anchor\" href=\"#3-医疗影像分析\">#</a> 3. 医疗影像分析</h4>\n<p>2D 视觉在辅助诊断方面发挥着越来越重要的作用。</p>\n<ul>\n<li>\n<p><strong>核心任务：</strong></p>\n<ul>\n<li><strong>病灶检测与分割：</strong> 在 X 光、CT 切片、MRI、病理切片中定位和勾画肿瘤、结节、出血点等。</li>\n<li><strong>分类与筛查：</strong> 判断影像是否异常（如胸片筛查肺结核、眼底照片筛查糖尿病视网膜病变）。</li>\n<li><strong>量化分析：</strong> 测量肿瘤大小、体积变化等。</li>\n</ul>\n</li>\n<li>\n<p><strong>主流技术栈：</strong></p>\n<ul>\n<li><strong>核心架构：</strong>\n<ul>\n<li><strong>U-Net：</strong> 在医学图像分割领域是<strong>事实上的标准</strong>，因其能有效利用有限的标注数据并产生精确的分割结果。</li>\n<li><strong>DeepLab 系列、nnUNet：</strong> nnUNet 是一个强大的自动化框架，在众多医学分割挑战中取得优异成绩。</li>\n</ul>\n</li>\n<li><strong>检测与分类：</strong>\n<ul>\n<li>使用在 ImageNet 上预训练的<strong> CNN 骨干网络</strong>（如 ResNet, DenseNet, EfficientNet）进行迁移学习，作为分类或检测模型的特征提取器。</li>\n</ul>\n</li>\n<li><strong>关键挑战与技术：</strong>\n<ul>\n<li><strong>数据量小、标注成本极高：</strong> 迁移学习、<strong>半监督学习</strong>（如 FixMatch）、<strong>自监督学习</strong>（先在无标签数据上预训练）是关键。</li>\n<li><strong>模型可解释性：</strong> 医生需要知道模型为何做出判断。<strong>类激活图</strong> 等技术可以高亮显示图像中对决策最重要的区域。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>实际考量：</strong></p>\n<ul>\n<li><strong>伦理与监管：</strong> 模型需通过严格的临床验证，并符合医疗器械监管标准（如 FDA、NMPA）。</li>\n<li><strong>模型必须是 “辅助” 角色：</strong> 最终诊断权在医生，系统需要提供置信度和可解释性。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"4-自动驾驶与智能交通\"><a class=\"markdownIt-Anchor\" href=\"#4-自动驾驶与智能交通\">#</a> 4. 自动驾驶与智能交通</h4>\n<p>虽然自动驾驶重度依赖 3D 感知，但其视觉子系统大量使用 2D 技术。</p>\n<ul>\n<li>\n<p><strong>核心任务：</strong></p>\n<ul>\n<li><strong>2D 目标检测：</strong> 实时检测车辆、行人、骑行者、交通标志、交通灯。</li>\n<li><strong>车道线检测：</strong> 识别车辆可行驶区域的车道线。</li>\n<li><strong>可行驶区域分割：</strong> 分割出道路区域。</li>\n<li><strong>多目标跟踪：</strong> 跟踪周围动态目标的运动轨迹。</li>\n</ul>\n</li>\n<li>\n<p><strong>主流技术栈：</strong></p>\n<ul>\n<li><strong>检测模型：</strong>\n<ul>\n<li><strong>YOLO 系列、SSD：</strong> 对实时性要求极高，单阶段检测器是主流。</li>\n<li><strong>CNN + FPN：</strong> 特征金字塔网络用于有效检测不同尺度的目标。</li>\n</ul>\n</li>\n<li><strong>分割模型：</strong>\n<ul>\n<li><strong>基于编码器 - 解码器的实时分割网络：</strong> 如<strong> DeepLabv3+</strong>（配合轻量级主干网）、<strong>BiSeNet</strong>（专为实时语义分割设计）。</li>\n</ul>\n</li>\n<li><strong>跟踪算法：</strong>\n<ul>\n<li><strong>SORT/DeepSORT：</strong> 经典的跟踪范式，使用卡尔曼滤波预测运动，并用外观特征（由小型 CNN 提取）进行数据关联。</li>\n</ul>\n</li>\n<li><strong>数据集：</strong>\n<ul>\n<li><strong>KITTI, BDD100K, Cityscapes</strong> 是公开的权威基准。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>实际考量：</strong></p>\n<ul>\n<li><strong>安全性第一：</strong> 任何错误都可能导致严重后果，要求模型有极高的召回率（尽可能不漏检）。</li>\n<li><strong>复杂场景：</strong> 天气变化、遮挡、光照变化剧烈，对模型的鲁棒性是巨大挑战。</li>\n<li><strong>系统集成：</strong> 2D 视觉结果通常需要与激光雷达、高精地图等 3D 信息进行融合，做出最终决策。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"5-零售与电商\"><a class=\"markdownIt-Anchor\" href=\"#5-零售与电商\">#</a> 5. 零售与电商</h4>\n<ul>\n<li>\n<p><strong>核心任务：</strong></p>\n<ul>\n<li><strong>智能货柜：</strong> 利用摄像头识别用户拿取的商品，实现自动结算。</li>\n<li><strong>商品识别与搜索：</strong> 拍照搜同款、商品自动分类。</li>\n<li><strong>顾客行为分析：</strong> 分析客流、热力图、顾客动线、停留时间。</li>\n</ul>\n</li>\n<li>\n<p><strong>主流技术栈：</strong></p>\n<ul>\n<li><strong>商品识别：</strong>\n<ul>\n<li><strong>检测 + 识别：</strong> 先用目标检测（YOLO）框出商品，再用分类网络（ResNet）识别具体品类。对于细粒度识别（不同型号的鞋子），需要更精细的网络设计。</li>\n<li><strong>度量学习：</strong> 类似人脸识别，将商品图像映射为特征向量，通过计算向量相似度来搜索同类商品。<strong>Triplet Loss</strong> 是常用方法。</li>\n</ul>\n</li>\n<li><strong>客流统计：</strong>\n<ul>\n<li>使用<strong>人体检测</strong>（YOLO）和<strong>跟踪</strong>（DeepSORT）来统计进出人数和轨迹。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>实际考量：</strong></p>\n<ul>\n<li><strong>SKU 繁多且更新快：</strong> 模型需要能够快速适应新商品，<strong>小样本学习</strong>和<strong>在线学习</strong>能力很重要。</li>\n<li><strong>对精度要求高：</strong> 直接关系到结算金额，不能出错。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h4 id=\"6-互联网娱乐与aigc\"><a class=\"markdownIt-Anchor\" href=\"#6-互联网娱乐与aigc\">#</a> 6. 互联网娱乐与 AIGC</h4>\n<p>这是近年来最火爆的方向。</p>\n<ul>\n<li>\n<p><strong>核心任务：</strong></p>\n<ul>\n<li><strong>图像分类与打标：</strong> 为相册、社交媒体图片自动添加标签。</li>\n<li><strong>人脸特效与美颜：</strong> 美颜相机、贴纸、年龄变化、表情迁移。</li>\n<li><strong>图像生成与编辑：</strong> 文生图、图生图、风格迁移、老照片修复、图像超分辨率。</li>\n</ul>\n</li>\n<li>\n<p><strong>主流技术栈：</strong></p>\n<ul>\n<li><strong>传统图像处理：</strong> OpenCV 中的滤波、形变、色彩调整等是美颜算法的基础。</li>\n<li><strong>人脸相关：</strong>\n<ul>\n<li><strong>人脸关键点检测：</strong> 用于精准贴纸、美颜（瘦脸、大眼）。</li>\n<li><strong>人脸分割：</strong> 用于虚化背景、染发试色。</li>\n<li><strong>GAN / 扩散模型：</strong> 用于生成虚拟形象、换脸等。</li>\n</ul>\n</li>\n<li><strong>生成式 AI：</strong>\n<ul>\n<li><strong>扩散模型：</strong> <strong>Stable Diffusion</strong> 是当前绝对的主流，用于文生图、图生图、inpainting（局部重绘）等。</li>\n<li><strong>GAN：</strong> StyleGAN 系列在高质量人脸生成上仍有应用。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>实际考量：</strong></p>\n<ul>\n<li><strong>追求视觉效果和创造性。</strong></li>\n<li><strong>对计算资源要求高：</strong> 尤其是扩散模型，推理需要强大的 GPU。</li>\n<li><strong>伦理问题：</strong> 深度伪造技术带来的滥用风险。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"总结\"><a class=\"markdownIt-Anchor\" href=\"#总结\">#</a> 总结</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">应用领域</th>\n<th style=\"text-align:left\">核心任务</th>\n<th style=\"text-align:left\">主流技术栈（模型 / 算法）</th>\n<th style=\"text-align:left\">关键工具 / 框架</th>\n<th style=\"text-align:left\">特殊考量</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>安防与监控</strong></td>\n<td style=\"text-align:left\">人脸识别、行为分析、车辆检测</td>\n<td style=\"text-align:left\">YOLO, SSD, ArcFace, DeepSORT, 3D CNN/LSTM</td>\n<td style=\"text-align:left\">OpenCV, PyTorch, TensorRT, OpenVINO</td>\n<td style=\"text-align:left\">实时性、边缘计算、鲁棒性、隐私</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>工业质检</strong></td>\n<td style=\"text-align:left\">缺陷检测、定位、OCR</td>\n<td style=\"text-align:left\">U-Net, AE/VAE（异常检测）, YOLO, 模板匹配，Blob 分析</td>\n<td style=\"text-align:left\">Halcon, OpenCV, PyTorch/TensorFlow</td>\n<td style=\"text-align:left\">高精度、环境可控、小样本缺陷</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>医疗影像</strong></td>\n<td style=\"text-align:left\">病灶分割、分类筛查</td>\n<td style=\"text-align:left\">U-Net, nnUNet, ResNet/DenseNet（迁移学习）</td>\n<td style=\"text-align:left\">PyTorch, TensorFlow, 类激活图</td>\n<td style=\"text-align:left\">数据稀缺、高标注成本、可解释性、法规</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>自动驾驶</strong></td>\n<td style=\"text-align:left\">2D 检测、车道线 / 可行驶区域分割</td>\n<td style=\"text-align:left\">YOLO, DeepLabv3+, BiSeNet, DeepSORT</td>\n<td style=\"text-align:left\">PyTorch, TensorRT, CUDA</td>\n<td style=\"text-align:left\">安全性、极端鲁棒性、多传感器融合</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>零售电商</strong></td>\n<td style=\"text-align:left\">商品识别、客流分析</td>\n<td style=\"text-align:left\">YOLO, ResNet（度量学习）, DeepSORT</td>\n<td style=\"text-align:left\">PyTorch, TensorFlow, OpenCV</td>\n<td style=\"text-align:left\">SKU 更新快、细粒度识别、结算精度</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>互联网娱乐</strong></td>\n<td style=\"text-align:left\">美颜、图像生成、标签推荐</td>\n<td style=\"text-align:left\">人脸关键点模型，Stable Diffusion, StyleGAN</td>\n<td style=\"text-align:left\">OpenCV, PyTorch, Diffusers 库</td>\n<td style=\"text-align:left\">计算资源、创意效果、伦理风险</td>\n</tr>\n</tbody>\n</table>\n",
            "tags": [
                "CV"
            ]
        },
        {
            "id": "https://lzq-cv.github.io/2025/09/27/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/",
            "url": "https://lzq-cv.github.io/2025/09/27/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/",
            "title": "2D视觉和3D视觉的主流技术栈",
            "date_published": "2025-09-27T01:38:14.000Z",
            "content_html": "<p>计算机视觉（CV）领域的主流技术栈，2D 视觉和 3D 视觉的技术、应用与区别。</p>\n<h3 id=\"一-计算机视觉技术栈总览\"><a class=\"markdownIt-Anchor\" href=\"#一-计算机视觉技术栈总览\">#</a> 一、 计算机视觉技术栈总览</h3>\n<p>计算机视觉的技术栈可以大致分为三个层次，从底层的基础工具到顶层的具体应用：</p>\n<ol>\n<li>\n<p><strong>底层基础层：</strong></p>\n<ul>\n<li><strong>编程语言：</strong> <strong>Python</strong> 是绝对的主流，因其丰富的库和社区生态。C++ 在需要高性能、低延迟的场合（如嵌入式、自动驾驶）中不可或缺。</li>\n<li><strong>数学基础：</strong> 线性代数、微积分、概率论、数值分析是理解算法的基石。</li>\n<li><strong>硬件：</strong> <strong>GPU（NVIDIA）</strong> 是训练和部署深度学习模型的核心。专用的 AI 芯片（如 Google TPU, NVIDIA Jetson, Intel Movidius）也在边缘计算中扮演重要角色。</li>\n</ul>\n</li>\n<li>\n<p><strong>核心工具与框架层：</strong></p>\n<ul>\n<li><strong>深度学习框架：</strong>\n<ul>\n<li><strong>PyTorch：</strong> 当前学术界和工业界的首选，以其动态图和简洁的 API 深受研究人员喜爱。</li>\n<li><strong>TensorFlow：</strong> 由 Google 支持，在工业界部署（尤其是使用 TensorFlow Lite, TensorRT 时）仍有强大优势。Keras 是其高级 API，易于上手。</li>\n</ul>\n</li>\n<li><strong>传统计算机视觉库：</strong>\n<ul>\n<li><strong>OpenCV：</strong> 计算机视觉的 “瑞士军刀”，提供了从图像 / 视频读写、预处理、几何变换、特征提取到目标检测（传统方法）等海量功能，是必备基础库。</li>\n</ul>\n</li>\n<li><strong>3D 视觉专用库：</strong>\n<ul>\n<li><strong>Open3D：</strong> 一个现代化的 3D 数据处理库，支持点云、网格的可视化、配准、重建等。</li>\n<li><strong>PCL：</strong> 点云库，功能非常强大但接口相对陈旧，在 C++ 项目中广泛使用。</li>\n<li><strong>VTK, ITK：</strong> 主要用于科学可视化和医学图像处理。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>模型与算法层：</strong></p>\n<ul>\n<li>这是技术栈的核心，下面将分 2D 和 3D 详细展开。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"二-2d-计算机视觉\"><a class=\"markdownIt-Anchor\" href=\"#二-2d-计算机视觉\">#</a> 二、 2D 计算机视觉</h3>\n<p>2D 视觉处理的是像素矩阵，即我们常见的 RGB 或灰度图像。</p>\n<h4 id=\"核心任务与技术\"><a class=\"markdownIt-Anchor\" href=\"#核心任务与技术\">#</a> 核心任务与技术</h4>\n<ol>\n<li>\n<p><strong>图像分类：</strong> 判断图像中包含什么物体。</p>\n<ul>\n<li><strong>核心技术：</strong> 卷积神经网络。</li>\n<li><strong>经典模型：</strong>\n<ul>\n<li><strong>开创者：</strong> AlexNet (2012)</li>\n<li><strong>深度代表：</strong> VGGNet</li>\n<li><strong>革新者：</strong> GoogLeNet (Inception 模块), ResNet (残差连接，解决了深层网络梯度消失问题)，这些模型至今仍是强大的<strong>骨干网络</strong>。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>目标检测：</strong> 找出图像中所有感兴趣物体的位置（用边界框表示）和类别。</p>\n<ul>\n<li><strong>两阶段检测器（精度高，速度慢）：</strong>\n<ul>\n<li><strong>R-CNN 系列：</strong> R-CNN -&gt; Fast R-CNN -&gt; <strong>Faster R-CNN</strong>。先产生候选区域，再对区域进行分类和微调。</li>\n</ul>\n</li>\n<li><strong>单阶段检测器（速度快，精度可媲美两阶段）：</strong>\n<ul>\n<li><strong>YOLO 系列：</strong> 特别是 <strong>v3, v5, v8, v9</strong>，将检测视为单一的回归问题，速度极快，是实时应用的首选。</li>\n<li><strong>SSD：</strong> 另一个经典的单阶段检测器。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>图像分割：</strong> 对每个像素进行分类，为每个物体生成精确的轮廓。</p>\n<ul>\n<li><strong>语义分割：</strong> 只区分类别，不区分个体（例如，图中所有的 “人” 都是同一类）。\n<ul>\n<li><strong>核心架构：</strong> <strong>编码器 - 解码器</strong>结构。编码器（如 ResNet）提取特征，解码器（如<strong> U-Net</strong>）恢复空间维度并进行像素级预测。<strong>DeepLab</strong> 系列（使用空洞卷积）也是主流。</li>\n</ul>\n</li>\n<li><strong>实例分割：</strong> 既区分类别，也区分不同的个体（例如，区分出第一个人，第二个人）。\n<ul>\n<li><strong>经典模型：</strong> <strong>Mask R-CNN</strong>，是在 Faster R-CNN 基础上的扩展，增加了一个分支来预测每个目标的二值掩码。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>关键点检测：</strong> 检测物体上具有特定意义的点。</p>\n<ul>\n<li><strong>应用：</strong> 人脸关键点（眼、鼻、嘴）、人体姿态估计（关节点的位置）。</li>\n<li><strong>典型方法：</strong> 通常建模为热图回归问题，即预测每个关键点可能出现的概率分布图。<strong>HRNet</strong> 是当前人体姿态估计的 SOTA 方法之一。</li>\n</ul>\n</li>\n<li>\n<p><strong>图像生成与编辑：</strong></p>\n<ul>\n<li><strong>生成对抗网络（GANs）：</strong> 如 StyleGAN 系列，用于生成逼真的人脸、艺术品等。</li>\n<li><strong>扩散模型：</strong> 如 Stable Diffusion、DALL-E，已成为图像生成的新范式，生成质量更高、更可控。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"2d视觉技术栈总结\"><a class=\"markdownIt-Anchor\" href=\"#2d视觉技术栈总结\">#</a> 2D 视觉技术栈总结</h4>\n<ul>\n<li><strong>输入：</strong> RGB 图像（H x W x 3）。</li>\n<li><strong>核心网络：</strong> <strong>卷积神经网络</strong>。</li>\n<li><strong>主要框架：</strong> PyTorch / TensorFlow + OpenCV。</li>\n<li><strong>趋势：</strong> Vision Transformer (ViT) 正在挑战 CNN 的统治地位，显示出强大的性能。轻量化模型（如 MobileNet, ShuffleNet）用于移动端和嵌入式设备是重要方向。</li>\n</ul>\n<hr>\n<h3 id=\"三-3d-计算机视觉\"><a class=\"markdownIt-Anchor\" href=\"#三-3d-计算机视觉\">#</a> 三、 3D 计算机视觉</h3>\n<p>3D 视觉旨在理解和重建三维世界的信息，其输入和数据表示形式远比 2D 丰富。</p>\n<h4 id=\"数据表示形式\"><a class=\"markdownIt-Anchor\" href=\"#数据表示形式\">#</a> 数据表示形式</h4>\n<ol>\n<li><strong>深度图：</strong> 每个像素的值代表该点到相机的距离。通常由 RGB-D 相机（如 Kinect, RealSense）或立体视觉直接获得。</li>\n<li><strong>点云：</strong> 一组三维空间中的点（x, y, z）的集合，可以包含颜色、法向量等信息。是激光雷达的直接输出。</li>\n<li><strong>体素网格：</strong> 将 3D 空间离散化为一个个小立方体（类似于 2D 的像素），是 3D 卷积的自然延伸，但内存消耗大。</li>\n<li><strong>网格：</strong> 由顶点、边和面（通常是三角面片）构成的曲面，是 3D 建模和渲染的通用格式。</li>\n<li><strong>多视图图像：</strong> 从不同视角拍摄的同一物体的多张 2D 图像，可通过运动恢复结构技术生成 3D 模型。</li>\n</ol>\n<h4 id=\"核心任务与技术-2\"><a class=\"markdownIt-Anchor\" href=\"#核心任务与技术-2\">#</a> 核心任务与技术</h4>\n<ol>\n<li>\n<p><strong>3D 重建：</strong> 从一组 2D 图像或深度传感器数据中恢复物体的 3D 模型。</p>\n<ul>\n<li><strong>运动恢复结构：</strong> 从多视角图像中计算相机姿态和稀疏的 3D 点云。</li>\n<li><strong>多视图立体视觉：</strong> 在 SfM 的基础上，生成稠密的 3D 点云或网格。</li>\n<li><strong>深度学习方法：</strong> 如 MVSNet 等，利用神经网络直接从多视图图像中学习生成深度图或点云。</li>\n</ul>\n</li>\n<li>\n<p><strong>点云处理：</strong></p>\n<ul>\n<li><strong>点云分类与分割：</strong> 对点云中的每个点或整个点云进行分类。\n<ul>\n<li><strong>开创性工作：</strong> <strong>PointNet</strong> / <strong>PointNet++</strong>，直接处理无序的点云集合。</li>\n<li><strong>后续发展：</strong> 基于图卷积、稀疏卷积（如<strong> Minkowski Engine</strong>）的方法能更好地捕捉局部特征。</li>\n</ul>\n</li>\n<li><strong>点云配准：</strong> 将不同视角扫描的点云对齐到同一个坐标系下。经典算法有 ICP，深度学习如 PointNetLK, DCP 等。</li>\n</ul>\n</li>\n<li>\n<p><strong>3D 目标检测：</strong></p>\n<ul>\n<li><strong>基于 LiDAR：</strong> 直接在点云中检测 3D bounding box（包含中心点、长宽高、朝向）。<strong>VoxelNet</strong>、<strong>PointPillars</strong>、<strong>SECOND</strong> 是经典且高效的模型。</li>\n<li><strong>基于视觉：</strong> 仅使用单目或双目 RGB 图像来估计 3D 框，难度更大，是当前研究热点。</li>\n<li><strong>多模态融合：</strong> 结合相机（RGB）和激光雷达（点云）的信息，提升检测精度，是自动驾驶领域的核心。</li>\n</ul>\n</li>\n<li>\n<p><strong>SLAM：</strong> 即时定位与地图构建。</p>\n<ul>\n<li>机器人在未知环境中移动，同时估计自身位置并构建环境地图。</li>\n<li><strong>视觉 SLAM：</strong> 使用单目、双目或 RGB-D 相机作为主要传感器。ORB-SLAM 系列是里程碑式的工作。</li>\n<li><strong>激光 SLAM：</strong> 使用激光雷达，如 LOAM、Cartographer，通常更精确。</li>\n</ul>\n</li>\n<li>\n<p><strong>神经辐射场：</strong> 一种革命性的 3D 场景表示和渲染技术。</p>\n<ul>\n<li><strong>核心思想（NeRF）：</strong> 用一个神经网络将空间位置和观看视角映射为颜色和密度，从而可以从任意视角生成逼真的新视图。衍生出了大量快速、动态的 NeRF 变体。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"3d视觉技术栈总结\"><a class=\"markdownIt-Anchor\" href=\"#3d视觉技术栈总结\">#</a> 3D 视觉技术栈总结</h4>\n<ul>\n<li><strong>输入：</strong> 点云、深度图、多视图图像等。</li>\n<li><strong>核心挑战：</strong> 数据的<strong>无序性</strong>（点云）、<strong>稀疏性</strong>、<strong>非结构化</strong>。</li>\n<li><strong>核心技术：</strong>\n<ul>\n<li><strong>传统几何方法：</strong> 多视图几何、光束法平差、ICP。</li>\n<li><strong>深度学习方法：</strong> 针对 3D 数据特化的网络（PointNet 系列、3D 稀疏卷积、Transformer）。</li>\n</ul>\n</li>\n<li><strong>主要框架：</strong> PyTorch / TensorFlow + Open3D / PCL。</li>\n</ul>\n<hr>\n<h3 id=\"四-2d视觉-vs-3d视觉-对比总结\"><a class=\"markdownIt-Anchor\" href=\"#四-2d视觉-vs-3d视觉-对比总结\">#</a> 四、 2D 视觉 vs. 3D 视觉 对比总结</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">特性</th>\n<th style=\"text-align:left\">2D 计算机视觉</th>\n<th style=\"text-align:left\">3D 计算机视觉</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>数据输入</strong></td>\n<td style=\"text-align:left\">二维像素矩阵（RGB / 灰度图）</td>\n<td style=\"text-align:left\">点云、深度图、多视图图像、网格等</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>信息维度</strong></td>\n<td style=\"text-align:left\">缺少深度和真实的几何信息</td>\n<td style=\"text-align:left\">包含丰富的三维几何和空间关系信息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>核心任务</strong></td>\n<td style=\"text-align:left\">分类、检测、分割（在像素层面）</td>\n<td style=\"text-align:left\">3D 重建、3D 检测、SLAM、点云处理</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>核心技术</strong></td>\n<td style=\"text-align:left\">卷积神经网络（CNN），Transformer</td>\n<td style=\"text-align:left\">多视图几何、点云网络（PointNet）、3D 卷积、神经辐射场（NeRF）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>应用场景</strong></td>\n<td style=\"text-align:left\">图像检索、照片美化、安防监控、图像内容审核</td>\n<td style=\"text-align:left\"><strong>自动驾驶</strong>、<strong>机器人导航</strong>、<strong>AR/VR</strong>、无人机、工业三维测量</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>数据获取</strong></td>\n<td style=\"text-align:left\">简单、廉价（普通摄像头）</td>\n<td style=\"text-align:left\">相对复杂、昂贵（RGB-D 相机、激光雷达）或需要计算（SfM）</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>挑战</strong></td>\n<td style=\"text-align:left\">光照变化、遮挡、视角变化、类内差异</td>\n<td style=\"text-align:left\">数据稀疏、噪声大、计算复杂度高、标注成本极高</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"五-融合与未来趋势\"><a class=\"markdownIt-Anchor\" href=\"#五-融合与未来趋势\">#</a> 五、 融合与未来趋势</h3>\n<p>未来的发展方向绝不是 2D 和 3D 的割裂，而是<strong>深度融合</strong>：</p>\n<ul>\n<li><strong>多模态学习：</strong> 将 2D 图像的丰富纹理和语义信息与 3D 数据的精确几何结构相结合。例如，在自动驾驶中，用 2D 检测的结果辅助 3D 检测，或者用 3D 信息为 2D 分割提供空间上下文。</li>\n<li><strong>2D 引导的 3D 理解：</strong> 利用在大型 2D 图像数据集（如 ImageNet）上预训练的模型，通过知识蒸馏或迁移学习来提升 3D 模型的性能，解决 3D 数据稀缺的问题。</li>\n<li><strong>AIGC 在 3D 中的应用：</strong> 利用扩散模型等生成式 AI 技术，从文本或单张图像直接生成高质量的 3D 模型（如 TripoSR、Shap-E 等），这将极大降低 3D 内容创作的门槛。</li>\n</ul>\n",
            "tags": [
                "CV"
            ]
        }
    ]
}