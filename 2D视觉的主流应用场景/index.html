<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Learning-Sharing-Recording" href="https://lzq-cv.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="Learning-Sharing-Recording" href="https://lzq-cv.github.io/atom.xml"><link rel="alternate" type="application/json" title="Learning-Sharing-Recording" href="https://lzq-cv.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="CV"><link rel="canonical" href="https://lzq-cv.github.io/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/"><title>2D视觉的主流应用场景 - Opencv - Computer-Vision | LZQ's Blog = Learning-Sharing-Recording = To be,or not to be,that is the question</title><meta name="generator" content="Hexo 8.0.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">2D视觉的主流应用场景</h1><div class="meta"><span class="item" title="Created: 2025-09-27 09:45:29"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2025-09-27T09:45:29+08:00">2025-09-27</time> </span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">Symbols count in article</span> <span>3.8k</span> <span class="text">words</span> </span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">Reading time</span> <span>3 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">LZQ's Blog</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://lzq-cv.oss-cn-shanghai.aliyuncs.com/149624-tian_kong-xing_neng-yi_shu-yin_le_hui-ren_qun-3840x2160.jpg"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Computer-Vision/" itemprop="item" rel="index" title="In Computer-Vision"><span itemprop="name">Computer-Vision</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Computer-Vision/Opencv/" itemprop="item" rel="index" title="In Opencv"><span itemprop="name">Opencv</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://lzq-cv.github.io/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="LZQ"><meta itemprop="description" content="To be,or not to be,that is the question, CV Engineer"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Learning-Sharing-Recording"></span><div class="body md" itemprop="articleBody"><h3 id="2d视觉主流应用场景与技术栈详解"><a class="anchor" href="#2d视觉主流应用场景与技术栈详解">#</a> 2D 视觉主流应用场景与技术栈详解</h3><p>主流的 2D 视觉应用分为以下几个大类。</p><hr><h4 id="1-安防与监控"><a class="anchor" href="#1-安防与监控">#</a> 1. 安防与监控</h4><p>这是 2D 视觉最经典、最广泛的应用领域。</p><ul><li><p><strong>核心任务：</strong></p><ul><li><strong>人脸识别与身份验证：</strong> 门禁系统、手机解锁、公共安全排查。</li><li><strong>人体检测与行为分析：</strong> 入侵检测、人群密度估计、徘徊检测、跌倒检测、打架斗殴识别。</li><li><strong>车辆识别与交通监控：</strong> 车牌识别、车辆违章检测（闯红灯、压线）、交通流量分析。</li><li><strong>物体遗留 / 消失检测：</strong> 在机场、火车站等场景检测可疑包裹。</li></ul></li><li><p><strong>主流技术栈：</strong></p><ul><li><strong>检测模型：</strong><ul><li><strong>YOLO 系列 (v5, v8, v9)：</strong> 绝对是该领域的首选，因其极高的速度和良好的精度，非常适合实时视频流分析。</li><li><strong>SSD, RetinaNet：</strong> 也是常用的单阶段检测器。</li></ul></li><li><strong>识别 / 分类模型：</strong><ul><li><strong>人脸识别：</strong> 使用专门的人脸检测（如 MTCNN、RetinaFace）加上人脸识别模型（如<strong> ArcFace</strong>、FaceNet、CosFace）。这些模型将人脸图像映射为一个高维特征向量，通过比对向量相似度进行身份识别。</li><li><strong>行为识别：</strong> 相对复杂，通常需要处理视频序列。技术包括：<ul><li><strong>3D CNN：</strong> 直接处理视频片段。</li><li><strong>CNN + RNN/LSTM：</strong> 用 CNN 提取每一帧的特征，再用 RNN/LSTM 学习时序关系。</li><li><strong>基于 Transformer 的方法：</strong> 如 TimeSformer，更好地捕捉长距离依赖。</li></ul></li></ul></li><li><strong>关键工具：</strong><ul><li><strong>OpenCV：</strong> 用于视频流捕获、图像预处理、绘制检测框、车牌识别中的字符分割等。</li><li><strong>深度学习框架：</strong> PyTorch（研究和新模型部署主流）、TensorFlow（现有系统较多）。</li><li><strong>部署工具：</strong> <strong>NVIDIA TensorRT</strong>（用于在 NVIDIA GPU 上极致加速推理）、<strong>OpenVINO</strong>（用于 Intel CPU/GPU 等硬件）。</li></ul></li></ul></li><li><p><strong>实际考量：</strong></p><ul><li><strong>实时性要求极高：</strong> 模型必须轻量化，通常需要在边缘设备（如 Jetson Nano、华为 Atlas）上运行。</li><li><strong>光照、角度变化大：</strong> 要求模型有很强的鲁棒性，数据增强（如随机亮度、对比度变化）非常重要。</li><li><strong>隐私问题：</strong> 需要遵循相关法律法规。</li></ul></li></ul><hr><h4 id="2-工业质检与自动化"><a class="anchor" href="#2-工业质检与自动化">#</a> 2. 工业质检与自动化</h4><p>这是 2D 视觉在工业界创造巨大价值的核心应用。</p><ul><li><p><strong>核心任务：</strong></p><ul><li><strong>缺陷检测：</strong> 检测产品表面的划痕、凹陷、污点、毛刺等。</li><li><strong>分类与分拣：</strong> 根据外观对产品进行合格 / 不合格分类，或按不同品类分拣。</li><li><strong>定位与引导：</strong> 精确识别零件的位置和姿态，引导机械臂进行抓取、装配。</li><li><strong>OCR 读取：</strong> 读取产品上的生产日期、批次号、序列号。</li></ul></li><li><p><strong>主流技术栈：</strong></p><ul><li><strong>缺陷检测：</strong><ul><li><strong>传统方法：</strong> 在规则、可控的照明环境下，传统算法依然非常有效且快速。例如，使用<strong> Blob 分析</strong>（找连通域）、<strong>模板匹配</strong>、<strong>形态学操作</strong>、<strong>频域滤波</strong>（如傅里叶变换找周期性缺陷）等。<strong>Halcon</strong> 和 <strong>VisionPro</strong> 是商业软件中的佼佼者。</li><li><strong>深度学习方法：</strong> 对于复杂、不规则的缺陷，深度学习是更好的选择。<ul><li><strong>语义分割：</strong> <strong>U-Net</strong> 及其变体是主流，可以像素级精确地定位缺陷区域。</li><li><strong>生成式方法：</strong> 使用<strong>自编码器</strong> 或<strong>生成对抗网络</strong> 学习正常样本的特征，然后通过重建误差来检测异常（缺陷被视为异常）。这种方法特别适合<strong>缺陷样本稀少</strong>的场景。</li></ul></li></ul></li><li><strong>定位与 OCR：</strong><ul><li><strong>定位：</strong> 通常使用<strong>模板匹配</strong>（传统）或训练一个目标检测模型（如 YOLO）来预测物体的边界框或角点。</li><li><strong>OCR：</strong> 通用场景可用 <strong>PaddleOCR</strong>、<strong>Tesseract</strong>。工业场景中字符通常规则且背景固定，也可以自己训练 CRNN（CNN+RNN+CTC）等模型，精度更高。</li></ul></li></ul></li><li><p><strong>实际考量：</strong></p><ul><li><strong>环境可控：</strong> 光照、相机位置、背景都是固定的，这是与安防场景的最大不同。</li><li><strong>精度要求极高：</strong> 漏检和误检的成本很高，模型评估指标（如 mAP, IoU）要求严格。</li><li><strong>速度要求：</strong> 需跟上生产线节奏，但通常不如安防实时性要求高。</li><li><strong>数据瓶颈：</strong> 缺陷样本难以收集，小样本学习和无监督 / 半监督方法备受关注。</li></ul></li></ul><hr><h4 id="3-医疗影像分析"><a class="anchor" href="#3-医疗影像分析">#</a> 3. 医疗影像分析</h4><p>2D 视觉在辅助诊断方面发挥着越来越重要的作用。</p><ul><li><p><strong>核心任务：</strong></p><ul><li><strong>病灶检测与分割：</strong> 在 X 光、CT 切片、MRI、病理切片中定位和勾画肿瘤、结节、出血点等。</li><li><strong>分类与筛查：</strong> 判断影像是否异常（如胸片筛查肺结核、眼底照片筛查糖尿病视网膜病变）。</li><li><strong>量化分析：</strong> 测量肿瘤大小、体积变化等。</li></ul></li><li><p><strong>主流技术栈：</strong></p><ul><li><strong>核心架构：</strong><ul><li><strong>U-Net：</strong> 在医学图像分割领域是<strong>事实上的标准</strong>，因其能有效利用有限的标注数据并产生精确的分割结果。</li><li><strong>DeepLab 系列、nnUNet：</strong> nnUNet 是一个强大的自动化框架，在众多医学分割挑战中取得优异成绩。</li></ul></li><li><strong>检测与分类：</strong><ul><li>使用在 ImageNet 上预训练的<strong> CNN 骨干网络</strong>（如 ResNet, DenseNet, EfficientNet）进行迁移学习，作为分类或检测模型的特征提取器。</li></ul></li><li><strong>关键挑战与技术：</strong><ul><li><strong>数据量小、标注成本极高：</strong> 迁移学习、<strong>半监督学习</strong>（如 FixMatch）、<strong>自监督学习</strong>（先在无标签数据上预训练）是关键。</li><li><strong>模型可解释性：</strong> 医生需要知道模型为何做出判断。<strong>类激活图</strong> 等技术可以高亮显示图像中对决策最重要的区域。</li></ul></li></ul></li><li><p><strong>实际考量：</strong></p><ul><li><strong>伦理与监管：</strong> 模型需通过严格的临床验证，并符合医疗器械监管标准（如 FDA、NMPA）。</li><li><strong>模型必须是 “辅助” 角色：</strong> 最终诊断权在医生，系统需要提供置信度和可解释性。</li></ul></li></ul><hr><h4 id="4-自动驾驶与智能交通"><a class="anchor" href="#4-自动驾驶与智能交通">#</a> 4. 自动驾驶与智能交通</h4><p>虽然自动驾驶重度依赖 3D 感知，但其视觉子系统大量使用 2D 技术。</p><ul><li><p><strong>核心任务：</strong></p><ul><li><strong>2D 目标检测：</strong> 实时检测车辆、行人、骑行者、交通标志、交通灯。</li><li><strong>车道线检测：</strong> 识别车辆可行驶区域的车道线。</li><li><strong>可行驶区域分割：</strong> 分割出道路区域。</li><li><strong>多目标跟踪：</strong> 跟踪周围动态目标的运动轨迹。</li></ul></li><li><p><strong>主流技术栈：</strong></p><ul><li><strong>检测模型：</strong><ul><li><strong>YOLO 系列、SSD：</strong> 对实时性要求极高，单阶段检测器是主流。</li><li><strong>CNN + FPN：</strong> 特征金字塔网络用于有效检测不同尺度的目标。</li></ul></li><li><strong>分割模型：</strong><ul><li><strong>基于编码器 - 解码器的实时分割网络：</strong> 如<strong> DeepLabv3+</strong>（配合轻量级主干网）、<strong>BiSeNet</strong>（专为实时语义分割设计）。</li></ul></li><li><strong>跟踪算法：</strong><ul><li><strong>SORT/DeepSORT：</strong> 经典的跟踪范式，使用卡尔曼滤波预测运动，并用外观特征（由小型 CNN 提取）进行数据关联。</li></ul></li><li><strong>数据集：</strong><ul><li><strong>KITTI, BDD100K, Cityscapes</strong> 是公开的权威基准。</li></ul></li></ul></li><li><p><strong>实际考量：</strong></p><ul><li><strong>安全性第一：</strong> 任何错误都可能导致严重后果，要求模型有极高的召回率（尽可能不漏检）。</li><li><strong>复杂场景：</strong> 天气变化、遮挡、光照变化剧烈，对模型的鲁棒性是巨大挑战。</li><li><strong>系统集成：</strong> 2D 视觉结果通常需要与激光雷达、高精地图等 3D 信息进行融合，做出最终决策。</li></ul></li></ul><hr><h4 id="5-零售与电商"><a class="anchor" href="#5-零售与电商">#</a> 5. 零售与电商</h4><ul><li><p><strong>核心任务：</strong></p><ul><li><strong>智能货柜：</strong> 利用摄像头识别用户拿取的商品，实现自动结算。</li><li><strong>商品识别与搜索：</strong> 拍照搜同款、商品自动分类。</li><li><strong>顾客行为分析：</strong> 分析客流、热力图、顾客动线、停留时间。</li></ul></li><li><p><strong>主流技术栈：</strong></p><ul><li><strong>商品识别：</strong><ul><li><strong>检测 + 识别：</strong> 先用目标检测（YOLO）框出商品，再用分类网络（ResNet）识别具体品类。对于细粒度识别（不同型号的鞋子），需要更精细的网络设计。</li><li><strong>度量学习：</strong> 类似人脸识别，将商品图像映射为特征向量，通过计算向量相似度来搜索同类商品。<strong>Triplet Loss</strong> 是常用方法。</li></ul></li><li><strong>客流统计：</strong><ul><li>使用<strong>人体检测</strong>（YOLO）和<strong>跟踪</strong>（DeepSORT）来统计进出人数和轨迹。</li></ul></li></ul></li><li><p><strong>实际考量：</strong></p><ul><li><strong>SKU 繁多且更新快：</strong> 模型需要能够快速适应新商品，<strong>小样本学习</strong>和<strong>在线学习</strong>能力很重要。</li><li><strong>对精度要求高：</strong> 直接关系到结算金额，不能出错。</li></ul></li></ul><hr><h4 id="6-互联网娱乐与aigc"><a class="anchor" href="#6-互联网娱乐与aigc">#</a> 6. 互联网娱乐与 AIGC</h4><p>这是近年来最火爆的方向。</p><ul><li><p><strong>核心任务：</strong></p><ul><li><strong>图像分类与打标：</strong> 为相册、社交媒体图片自动添加标签。</li><li><strong>人脸特效与美颜：</strong> 美颜相机、贴纸、年龄变化、表情迁移。</li><li><strong>图像生成与编辑：</strong> 文生图、图生图、风格迁移、老照片修复、图像超分辨率。</li></ul></li><li><p><strong>主流技术栈：</strong></p><ul><li><strong>传统图像处理：</strong> OpenCV 中的滤波、形变、色彩调整等是美颜算法的基础。</li><li><strong>人脸相关：</strong><ul><li><strong>人脸关键点检测：</strong> 用于精准贴纸、美颜（瘦脸、大眼）。</li><li><strong>人脸分割：</strong> 用于虚化背景、染发试色。</li><li><strong>GAN / 扩散模型：</strong> 用于生成虚拟形象、换脸等。</li></ul></li><li><strong>生成式 AI：</strong><ul><li><strong>扩散模型：</strong> <strong>Stable Diffusion</strong> 是当前绝对的主流，用于文生图、图生图、inpainting（局部重绘）等。</li><li><strong>GAN：</strong> StyleGAN 系列在高质量人脸生成上仍有应用。</li></ul></li></ul></li><li><p><strong>实际考量：</strong></p><ul><li><strong>追求视觉效果和创造性。</strong></li><li><strong>对计算资源要求高：</strong> 尤其是扩散模型，推理需要强大的 GPU。</li><li><strong>伦理问题：</strong> 深度伪造技术带来的滥用风险。</li></ul></li></ul><h3 id="总结"><a class="anchor" href="#总结">#</a> 总结</h3><table><thead><tr><th style="text-align:left">应用领域</th><th style="text-align:left">核心任务</th><th style="text-align:left">主流技术栈（模型 / 算法）</th><th style="text-align:left">关键工具 / 框架</th><th style="text-align:left">特殊考量</th></tr></thead><tbody><tr><td style="text-align:left"><strong>安防与监控</strong></td><td style="text-align:left">人脸识别、行为分析、车辆检测</td><td style="text-align:left">YOLO, SSD, ArcFace, DeepSORT, 3D CNN/LSTM</td><td style="text-align:left">OpenCV, PyTorch, TensorRT, OpenVINO</td><td style="text-align:left">实时性、边缘计算、鲁棒性、隐私</td></tr><tr><td style="text-align:left"><strong>工业质检</strong></td><td style="text-align:left">缺陷检测、定位、OCR</td><td style="text-align:left">U-Net, AE/VAE（异常检测）, YOLO, 模板匹配，Blob 分析</td><td style="text-align:left">Halcon, OpenCV, PyTorch/TensorFlow</td><td style="text-align:left">高精度、环境可控、小样本缺陷</td></tr><tr><td style="text-align:left"><strong>医疗影像</strong></td><td style="text-align:left">病灶分割、分类筛查</td><td style="text-align:left">U-Net, nnUNet, ResNet/DenseNet（迁移学习）</td><td style="text-align:left">PyTorch, TensorFlow, 类激活图</td><td style="text-align:left">数据稀缺、高标注成本、可解释性、法规</td></tr><tr><td style="text-align:left"><strong>自动驾驶</strong></td><td style="text-align:left">2D 检测、车道线 / 可行驶区域分割</td><td style="text-align:left">YOLO, DeepLabv3+, BiSeNet, DeepSORT</td><td style="text-align:left">PyTorch, TensorRT, CUDA</td><td style="text-align:left">安全性、极端鲁棒性、多传感器融合</td></tr><tr><td style="text-align:left"><strong>零售电商</strong></td><td style="text-align:left">商品识别、客流分析</td><td style="text-align:left">YOLO, ResNet（度量学习）, DeepSORT</td><td style="text-align:left">PyTorch, TensorFlow, OpenCV</td><td style="text-align:left">SKU 更新快、细粒度识别、结算精度</td></tr><tr><td style="text-align:left"><strong>互联网娱乐</strong></td><td style="text-align:left">美颜、图像生成、标签推荐</td><td style="text-align:left">人脸关键点模型，Stable Diffusion, StyleGAN</td><td style="text-align:left">OpenCV, PyTorch, Diffusers 库</td><td style="text-align:left">计算资源、创意效果、伦理风险</td></tr></tbody></table><div class="tags"><a href="/tags/CV/" rel="tag"><i class="ic i-tag"></i> CV</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2025-09-29 09:06:01" itemprop="dateModified" datetime="2025-09-29T09:06:01+08:00">2025-09-29</time> </span><span id="2D视觉的主流应用场景/" class="item leancloud_visitors" data-flag-title="2D视觉的主流应用场景" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">Views</span> <span class="leancloud-visitors-count"></span> <span class="text">times</span></span></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>LZQ <i class="ic i-at"><em>@</em></i>Learning-Sharing-Recording</li><li class="link"><strong>Post link: </strong><a href="https://lzq-cv.github.io/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" title="2D视觉的主流应用场景">https://lzq-cv.github.io/2D视觉的主流应用场景/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;lzq-cv.oss-cn-shanghai.aliyuncs.com&#x2F;05bca4a24ba140b8b8e68b7be3cdc18a.jpg" title="2D视觉和3D视觉的主流技术栈"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> Opencv</span><h3>2D视觉和3D视觉的主流技术栈</h3></a></div><div class="item right"><a href="/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;lzq-cv.oss-cn-shanghai.aliyuncs.com&#x2F;f6a8faacd278df962fcd1d4180baf2ac.jpg" title="PyTorch深度学习框架搭建"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> Deep-Learning</span><h3>PyTorch深度学习框架搭建</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#2d%E8%A7%86%E8%A7%89%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8E%E6%8A%80%E6%9C%AF%E6%A0%88%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.</span> <span class="toc-text">2D 视觉主流应用场景与技术栈详解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%AE%89%E9%98%B2%E4%B8%8E%E7%9B%91%E6%8E%A7"><span class="toc-number">1.1.</span> <span class="toc-text">1. 安防与监控</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%B7%A5%E4%B8%9A%E8%B4%A8%E6%A3%80%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96"><span class="toc-number">1.2.</span> <span class="toc-text">2. 工业质检与自动化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E5%8C%BB%E7%96%97%E5%BD%B1%E5%83%8F%E5%88%86%E6%9E%90"><span class="toc-number">1.3.</span> <span class="toc-text">3. 医疗影像分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%B8%8E%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A"><span class="toc-number">1.4.</span> <span class="toc-text">4. 自动驾驶与智能交通</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E9%9B%B6%E5%94%AE%E4%B8%8E%E7%94%B5%E5%95%86"><span class="toc-number">1.5.</span> <span class="toc-text">5. 零售与电商</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-%E4%BA%92%E8%81%94%E7%BD%91%E5%A8%B1%E4%B9%90%E4%B8%8Eaigc"><span class="toc-number">1.6.</span> <span class="toc-text">6. 互联网娱乐与 AIGC</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.</span> <span class="toc-text">总结</span></a></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/" rel="bookmark" title="2D视觉和3D视觉的主流技术栈">2D视觉和3D视觉的主流技术栈</a></li><li class="active"><a href="/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" rel="bookmark" title="2D视觉的主流应用场景">2D视觉的主流应用场景</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="LZQ" data-src="/images/avatar.jpg"><p class="name" itemprop="name">LZQ</p><div class="description" itemprop="description">CV Engineer</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">15</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">4</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">10</span> <span class="name">tags</span></a></div></nav><div class="social"><span class="exturl item bilibili" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vODI2ODE4NDY/c3BtX2lkX2Zyb209MzMzLjEwMDcuMC4w" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;82681846?spm_id_from&#x3D;333.1007.0.0"><i class="ic i-bilibili"></i></span> <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0xaUS1DVg==" title="https:&#x2F;&#x2F;github.com&#x2F;LZQ-CV"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9tYW8tcWl1LWNoYW5nLWx6cQ==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mao-qiu-chang-lzq"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTMzNjM5NDU5MTA=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;3363945910"><i class="ic i-cloud-music"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>Posts</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2D%E8%A7%86%E8%A7%89%E5%92%8C3D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E6%8A%80%E6%9C%AF%E6%A0%88/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Vision/" title="In Computer-Vision">Computer-Vision</a> <i class="ic i-angle-right"></i> <a href="/categories/Computer-Vision/Opencv/" title="In Opencv">Opencv</a></div><span><a href="/2D%E8%A7%86%E8%A7%89%E7%9A%84%E4%B8%BB%E6%B5%81%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" title="2D视觉的主流应用场景">2D视觉的主流应用场景</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E7%A1%AC%E4%BB%B6%E5%A6%82%E4%BD%95%E9%80%89%E5%9E%8B/" title="机器视觉硬件如何选型">机器视觉硬件如何选型</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Artificial-Intelligence/" title="In Artificial-Intelligence">Artificial-Intelligence</a> <i class="ic i-angle-right"></i> <a href="/categories/Artificial-Intelligence/Deep-Learning/" title="In Deep-Learning">Deep-Learning</a></div><span><a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%9C%AF%E8%AF%AD/" title="机器学习和深度学习的主要术语">机器学习和深度学习的主要术语</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E4%BD%BF%E7%94%A8PICGO-GitHub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/" title="使用PICGO-GitHub搭建个人图床">使用PICGO-GitHub搭建个人图床</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Artificial-Intelligence/" title="In Artificial-Intelligence">Artificial-Intelligence</a> <i class="ic i-angle-right"></i> <a href="/categories/Artificial-Intelligence/Deep-Learning/" title="In Deep-Learning">Deep-Learning</a></div><span><a href="/100%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%AF%E8%AF%AD/" title="100个深度学习术语">100个深度学习术语</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/python%E9%81%8D%E5%8E%86%E6%8C%87%E5%AE%9A%E8%B7%AF%E5%BE%84%E7%9A%84%E5%9B%BE%E7%89%87/" title="python遍历指定路径的图片">python遍历指定路径的图片</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/LAMP%E5%92%8CLNMP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8C%BA%E5%88%AB/" title="LAMP和LNMP服务器架构的区别">LAMP和LNMP服务器架构的区别</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E4%BD%BF%E7%94%A8PICGO-%E9%98%BF%E9%87%8C%E4%BA%91OSS%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/" title="使用PICGO-阿里云OSS搭建个人图床">使用PICGO-阿里云OSS搭建个人图床</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/shoka%E4%B8%BB%E9%A2%98%E9%83%A8%E7%BD%B2/" title="shoka主题部署">shoka主题部署</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/hello-world/" title="Hello World">Hello World</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2024 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">LZQ @ LZQ's Blog</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="Symbols count total">38k words</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="Reading time total">35 mins.</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2D视觉的主流应用场景/",favicon:{show:"（●´3｀●）Nice to meet you.",hide:"(´Д｀)You'll be back !!!"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>